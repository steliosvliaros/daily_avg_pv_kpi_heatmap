{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using List: DEV | Blng typical plan (id=901520251480)\n",
      "Custom field \"task type\" not found on the List. (Will still set dates/time/deps; type will be skipped.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SPACE_ID  = \"90159483029\"\n",
    "# Correct folder id for 99 DEV | Templates (from enumeration):\n",
    "FOLDER_ID = \"901513517686\"\n",
    "\n",
    "TASK_TEMPLATE_ID = \"t-86c7n8hr7\"   # \"DEV | Typical Task\"\n",
    "CSV_PATH = \"OITILO_ClickUp_WBS__dependencies___full_task_name_.csv\"  # <-- put your CSV filename/path here\n",
    "LIST_NAME = \"DEV | Blng typical plan\"         # target list name inside the folder (created if missing)\n",
    "\n",
    "# Use env var if you can; fallback to provided token\n",
    "# In notebook: os.environ[\"CLICKUP_TOKEN\"] = \"pk_....\"\n",
    "CLICKUP_TOKEN = os.getenv(\"CLICKUP_TOKEN\") or \"pk_56660333_WATA0RDNID48ZA30VX30Z2CRSNB16SN3\"\n",
    "\n",
    "DRY_RUN = False\n",
    "\n",
    "BASE = \"https://api.clickup.com/api/v2\"\n",
    "\n",
    "# =========================\n",
    "# HTTP helper (retry 429/5xx)\n",
    "# =========================\n",
    "sess = requests.Session()\n",
    "# ClickUp Personal Token uses raw token (no \"Bearer\")\n",
    "sess.headers.update({\n",
    "    \"Authorization\": CLICKUP_TOKEN,\n",
    "    \"Accept\": \"application/json\",\n",
    "})\n",
    "\n",
    "def req(method: str, url: str, *, params=None, json=None, ok=(200, 201), retries=6):\n",
    "    if DRY_RUN:\n",
    "        print(f\"[DRY_RUN] {method} {url} params={params} json={json}\")\n",
    "        return {}\n",
    "    last = None\n",
    "    for i in range(retries):\n",
    "        r = sess.request(method, url, params=params, json=json, timeout=60)\n",
    "        if r.status_code in ok:\n",
    "            return r.json() if r.text else {}\n",
    "        if r.status_code == 429 or r.status_code >= 500:\n",
    "            wait = min(60, 2 ** i)\n",
    "            time.sleep(wait)\n",
    "            last = (r.status_code, r.text[:400])\n",
    "            continue\n",
    "        # Improved diagnostics for non-retryable errors\n",
    "        snippet = (r.text or \"\")[:400]\n",
    "        raise RuntimeError(f\"{method} {url} failed: {r.status_code} {snippet}\")\n",
    "    raise RuntimeError(f\"{method} {url} failed after retries. Last error: {last}\")\n",
    "\n",
    "def date_to_ms_midday_utc(date_str: str) -> int:\n",
    "    # noon UTC to avoid day shifting from timezone conversions\n",
    "    d = datetime.strptime(date_str, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) + timedelta(hours=12)\n",
    "    return int(d.timestamp() * 1000)\n",
    "\n",
    "def days_to_ms(days: float) -> int:\n",
    "    return int(float(days) * 24 * 60 * 60 * 1000)\n",
    "\n",
    "def split_deps(dep_cell) -> list[str]:\n",
    "    if dep_cell is None or (isinstance(dep_cell, float) and pd.isna(dep_cell)):\n",
    "        return []\n",
    "    s = str(dep_cell).strip()\n",
    "    if not s or s.lower() == \"nan\":\n",
    "        return []\n",
    "    # allow ; , greek semicolon, etc.\n",
    "    parts = []\n",
    "    for chunk in s.replace(\"；\", \";\").replace(\",\", \";\").split(\";\"):\n",
    "        c = chunk.strip()\n",
    "        if c:\n",
    "            parts.append(c)\n",
    "    return parts\n",
    "\n",
    "# =========================\n",
    "# 1) Load CSV\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "required = [\"TASK NAME\", \"dependencies\", \"start date\", \"due date\", \"task type\", \"estimated time\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "df = df.copy()\n",
    "df[\"TASK NAME\"] = df[\"TASK NAME\"].astype(str).str.strip()\n",
    "df[\"task type\"] = df[\"task type\"].astype(str).str.strip().str.lower()\n",
    "df[\"start date\"] = df[\"start date\"].astype(str).str.strip()\n",
    "df[\"due date\"] = df[\"due date\"].astype(str).str.strip()\n",
    "\n",
    "# Optional: sort by start date then name for nicer creation order\n",
    "def safe_dt(s):\n",
    "    try:\n",
    "        return datetime.strptime(s, \"%Y-%m-%d\")\n",
    "    except:\n",
    "        return datetime(2100, 1, 1)\n",
    "\n",
    "df = df.sort_values(by=[\"start date\", \"TASK NAME\"], key=lambda col: col.map(safe_dt) if col.name==\"start date\" else col).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) Get or create target List inside Folder\n",
    "# =========================\n",
    "lists = req(\"GET\", f\"{BASE}/folder/{FOLDER_ID}/list\", params={\"archived\": \"false\"}).get(\"lists\", [])\n",
    "\n",
    "list_id = None\n",
    "for l in lists:\n",
    "    if str(l.get(\"name\", \"\")).strip().lower() == LIST_NAME.strip().lower():\n",
    "        list_id = str(l[\"id\"])\n",
    "        break\n",
    "\n",
    "if list_id is None:\n",
    "    created = req(\"POST\", f\"{BASE}/folder/{FOLDER_ID}/list\", json={\"name\": LIST_NAME})\n",
    "    list_id = str(created[\"id\"])\n",
    "\n",
    "print(f\"Using List: {LIST_NAME} (id={list_id})\")\n",
    "\n",
    "# =========================\n",
    "# 3) Detect custom field \"task type\" (dropdown) on that List\n",
    "#     and map 'task'/'milestone' labels -> option IDs\n",
    "# =========================\n",
    "task_type_field_id = None\n",
    "task_type_option_ids = {}  # {\"task\": <opt_id>, \"milestone\": <opt_id>}\n",
    "\n",
    "fields = req(\"GET\", f\"{BASE}/list/{list_id}/field\").get(\"fields\", [])\n",
    "for f in fields:\n",
    "    if str(f.get(\"name\", \"\")).strip().lower() == \"task type\":\n",
    "        task_type_field_id = str(f.get(\"id\"))\n",
    "        # dropdown options are typically in type_config.options\n",
    "        opts = (f.get(\"type_config\") or {}).get(\"options\") or []\n",
    "        for o in opts:\n",
    "            label = str(o.get(\"name\", \"\")).strip().lower()\n",
    "            if label in (\"task\", \"milestone\"):\n",
    "                task_type_option_ids[label] = o.get(\"id\")\n",
    "        break\n",
    "\n",
    "if task_type_field_id:\n",
    "    print(f'Found custom field \"task type\" id={task_type_field_id}, options={task_type_option_ids}')\n",
    "else:\n",
    "    print('Custom field \"task type\" not found on the List. (Will still set dates/time/deps; type will be skipped.)')\n",
    "\n",
    "# =========================\n",
    "# 4) Create tasks from template + set start/due/time estimate + task type\n",
    "# =========================\n",
    "name_to_id = {}\n",
    "\n",
    "created_cnt = 0\n",
    "updated_cnt = 0\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    name = r[\"TASK NAME\"]\n",
    "\n",
    "    # Create from template\n",
    "    created = req(\n",
    "        \"POST\",\n",
    "        f\"{BASE}/list/{list_id}/taskTemplate/{TASK_TEMPLATE_ID}\",\n",
    "        json={\"name\": name},\n",
    "        ok=(200, 201),\n",
    "    )\n",
    "\n",
    "    task_id = str(created.get(\"id\") or created.get(\"task\", {}).get(\"id\") or \"\")\n",
    "    if not task_id:\n",
    "        raise RuntimeError(f\"Could not parse created task id for '{name}'. Response: {created}\")\n",
    "\n",
    "    name_to_id[name] = task_id\n",
    "    created_cnt += 1\n",
    "\n",
    "    # Update fields: start_date, due_date, time_estimate, + custom field \"task type\" (dropdown)\n",
    "    payload = {}\n",
    "\n",
    "    sd = r[\"start date\"]\n",
    "    dd = r[\"due date\"]\n",
    "    if sd and sd.lower() != \"nan\":\n",
    "        payload[\"start_date\"] = date_to_ms_midday_utc(sd)\n",
    "        payload[\"start_date_time\"] = False\n",
    "    if dd and dd.lower() != \"nan\":\n",
    "        payload[\"due_date\"] = date_to_ms_midday_utc(dd)\n",
    "        payload[\"due_date_time\"] = False\n",
    "\n",
    "    est = r[\"estimated time\"]\n",
    "    if est is not None and not (isinstance(est, float) and pd.isna(est)):\n",
    "        try:\n",
    "            payload[\"time_estimate\"] = days_to_ms(float(est))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Set task type via custom field \"task type\" (dropdown)\n",
    "    tt = r[\"task type\"]\n",
    "    if task_type_field_id and tt in task_type_option_ids:\n",
    "        payload[\"custom_fields\"] = [{\n",
    "            \"id\": task_type_field_id,\n",
    "            \"value\": task_type_option_ids[tt]\n",
    "        }]\n",
    "\n",
    "    if payload:\n",
    "        req(\"PUT\", f\"{BASE}/task/{task_id}\", json=payload, ok=(200,))\n",
    "        updated_cnt += 1\n",
    "\n",
    "print(f\"Created: {created_cnt} | Updated (dates/time/type): {updated_cnt}\")\n",
    "\n",
    "# =========================\n",
    "# 5) Add dependencies (depends_on) using FULL TASK NAME mapping\n",
    "# =========================\n",
    "deps_added = 0\n",
    "deps_missing = 0\n",
    "deps_already = 0\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    child_name = r[\"TASK NAME\"]\n",
    "    child_id = name_to_id.get(child_name)\n",
    "    if not child_id:\n",
    "        continue\n",
    "\n",
    "    for parent_name in split_deps(r[\"dependencies\"]):\n",
    "        parent_id = name_to_id.get(parent_name)\n",
    "        if not parent_id:\n",
    "            deps_missing += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            req(\n",
    "                \"POST\",\n",
    "                f\"{BASE}/task/{child_id}/dependency\",\n",
    "                json={\"depends_on\": parent_id},\n",
    "                ok=(200, 201),\n",
    "            )\n",
    "            deps_added += 1\n",
    "        except RuntimeError as e:\n",
    "            # often ClickUp returns an error if dependency already exists\n",
    "            if \"already\" in str(e).lower() or \"exist\" in str(e).lower():\n",
    "                deps_already += 1\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "print(f\"Dependencies added: {deps_added} | Missing-mapped deps: {deps_missing} | Already existed: {deps_already}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b697c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token prefix: pk_566…\n",
      "Team task templates OK, count: 0\n",
      "Folder OK: Oitilo (id= 901513316704 )\n",
      "Lists OK, count: 1\n"
     ]
    }
   ],
   "source": [
    "# Quick diagnostics to verify token + IDs access\n",
    "print(\"Token prefix:\", (CLICKUP_TOKEN[:6] + \"…\"))\n",
    "\n",
    "# 1) Sanity: team templates (you said this works)\n",
    "try:\n",
    "    team_templates = req(\"GET\", f\"{BASE}/team/{SPACE_ID}/taskTemplate\")\n",
    "    count = len(team_templates.get(\"task_templates\", [])) if isinstance(team_templates, dict) else None\n",
    "    print(\"Team task templates OK, count:\", count)\n",
    "except Exception as e:\n",
    "    print(\"Team task templates FAIL:\", e)\n",
    "\n",
    "# 2) Folder details (ensures token can see this folder)\n",
    "try:\n",
    "    folder = req(\"GET\", f\"{BASE}/folder/{FOLDER_ID}\")\n",
    "    print(\"Folder OK:\", folder.get(\"name\"), \"(id=\", folder.get(\"id\"), \")\")\n",
    "except Exception as e:\n",
    "    print(\"Folder FAIL:\", e)\n",
    "\n",
    "# 3) Lists in folder (this is what main flow uses)\n",
    "try:\n",
    "    lists = req(\"GET\", f\"{BASE}/folder/{FOLDER_ID}/list\", params={\"archived\": \"false\"})\n",
    "    print(\"Lists OK, count:\", len(lists.get(\"lists\", [])))\n",
    "except Exception as e:\n",
    "    print(\"Lists FAIL:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49c9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token prefix: pk_566…\n",
      "Workspace/Team id used (SPACE_ID var): 90152198197\n",
      "Spaces visible: 5\n",
      "\n",
      "Space: OPS – Work Orders (id=90159268305)\n",
      "  Folders: 2\n",
      "   - Folder: ASSET O&M (id=901513201204)\n",
      "       Lists: 6 (access OK)\n",
      "   - Folder: PV O&M (id=901513226829)\n",
      "       Lists: 6 (access OK)\n",
      "\n",
      "Space: PROJECTS – CAPEX & Delivery (id=90159268307)\n",
      "  Folders: 5\n",
      "   - Folder: test_me (id=901513223215)\n",
      "       Lists: 3 (access OK)\n",
      "   - Folder: CAPEX & Upgrades (id=901513201222)\n",
      "       Lists: 1 (access OK)\n",
      "   - Folder: Projects – Dev & Construction (id=901513201233)\n",
      "       Lists: 1 (access OK)\n",
      "   - Folder: DC – 12MW IT / 19.5MW Total – Tier III N+1 – Northern Greece (id=901513254092)\n",
      "       Lists: 6 (access OK)\n",
      "   - Folder: Oitilo (id=901513316704)\n",
      "       Lists: 1 (access OK)\n",
      "\n",
      "Space: FINANCE + CONTROL (id=90159268308)\n",
      "  Folders: 3\n",
      "   - Folder: Finance Control (id=901513201239)\n",
      "       Lists: 1 (access OK)\n",
      "   - Folder: Governance (id=901513201246)\n",
      "       Lists: 2 (access OK)\n",
      "   - Folder: Vendor Management (id=901513253838)\n",
      "       Lists: 1 (access OK)\n",
      "\n",
      "Space: HQ (id=90159294333)\n",
      "  Folders: 0\n",
      "\n",
      "Space: DEV | Development (GR) (id=90159483029)\n",
      "  Folders: 6\n",
      "   - Folder: 10 PV | Utility-scale (id=901513510766)\n",
      "       Lists: 0 (access OK)\n",
      "   - Folder: 20 DATACENTER | Utility-scale (id=901513518041)\n",
      "       Lists: 0 (access OK)\n",
      "   - Folder: 30 BIOCHAR | Utility-scale (id=901513520288)\n",
      "       Lists: 0 (access OK)\n",
      "   - Folder: 40 HYDROPONICS | Utility-scale (id=901513520317)\n",
      "       Lists: 1 (access OK)\n",
      "   - Folder: 99 DEV | Templates (id=901513517686)\n",
      "       Lists: 5 (access OK)\n",
      "   - Folder: DATA CENTERS (id=901513568369)\n",
      "       Lists: 1 (access OK)\n"
     ]
    }
   ],
   "source": [
    "# Enumerate spaces and folders accessible by this token\n",
    "print(\"Token prefix:\", (CLICKUP_TOKEN[:6] + \"…\"))\n",
    "print(\"Workspace/Team id used (SPACE_ID var):\", SPACE_ID)\n",
    "\n",
    "# 1) List spaces under the team/workspace\n",
    "try:\n",
    "    spaces = req(\"GET\", f\"{BASE}/team/{SPACE_ID}/space\", params={\"archived\": \"false\"}).get(\"spaces\", [])\n",
    "    print(f\"Spaces visible: {len(spaces)}\")\n",
    "except Exception as e:\n",
    "    print(\"Spaces FAIL:\", e)\n",
    "    spaces = []\n",
    "\n",
    "# 2) For each space, list folders\n",
    "for s in spaces:\n",
    "    sid = str(s.get(\"id\"))\n",
    "    sname = s.get(\"name\")\n",
    "    print(f\"\\nSpace: {sname} (id={sid})\")\n",
    "    try:\n",
    "        folders = req(\"GET\", f\"{BASE}/space/{sid}/folder\", params={\"archived\": \"false\"}).get(\"folders\", [])\n",
    "        print(f\"  Folders: {len(folders)}\")\n",
    "        for f in folders:\n",
    "            fid = str(f.get(\"id\"))\n",
    "            fname = f.get(\"name\")\n",
    "            print(f\"   - Folder: {fname} (id={fid})\")\n",
    "            # probe lists to ensure access\n",
    "            try:\n",
    "                lists = req(\"GET\", f\"{BASE}/folder/{fid}/list\", params={\"archived\": \"false\"}).get(\"lists\", [])\n",
    "                print(f\"       Lists: {len(lists)} (access OK)\")\n",
    "            except Exception as e:\n",
    "                print(f\"       Lists probe FAIL: {e}\")\n",
    "    except Exception as e:\n",
    "        print(\"  Folders FAIL:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9031cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth header updated. Using Bearer: False | Token prefix: pk_566…\n"
     ]
    }
   ],
   "source": [
    "# Override ClickUp token in-session and refresh headers\n",
    "import os\n",
    "try:\n",
    "    sess\n",
    "except NameError:\n",
    "    import requests\n",
    "    sess = requests.Session()\n",
    "    sess.headers.update({\"Accept\": \"application/json\"})\n",
    "\n",
    "# Paste token below or set env var CLICKUP_TOKEN before running\n",
    "PASTE_TOKEN = \"\"  # <-- optionally paste token here, else leave blank to use env\n",
    "if PASTE_TOKEN:\n",
    "    os.environ[\"CLICKUP_TOKEN\"] = PASTE_TOKEN\n",
    "\n",
    "# Refresh variables and header\n",
    "CLICKUP_TOKEN = os.getenv(\"CLICKUP_TOKEN\") or CLICKUP_TOKEN\n",
    "USE_BEARER = False  # set True if your org requires Bearer format\n",
    "sess.headers[\"Authorization\"] = (f\"Bearer {CLICKUP_TOKEN}\" if USE_BEARER else CLICKUP_TOKEN)\n",
    "print(\"Auth header updated. Using Bearer:\", USE_BEARER, \"| Token prefix:\", (CLICKUP_TOKEN[:6] + \"…\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pv-kpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
